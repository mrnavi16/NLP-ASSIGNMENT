{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiRwu8RSrUPC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Function to work out the distinct words (word types) that occur in the corpus.\n",
        "def distinct_words(corpus):\n",
        "    return list(set(corpus))\n",
        "\n",
        "# Function to construct a co-occurrence matrix for a certain window-size n\n",
        "def co_occurrence_matrix(corpus, window_size=4):\n",
        "    words = distinct_words(corpus)\n",
        "    word_to_index = {word: i for i, word in enumerate(words)}\n",
        "    num_words = len(words)\n",
        "    co_matrix = np.zeros((num_words, num_words), dtype=int)\n",
        "\n",
        "    for i, target_word in enumerate(corpus):\n",
        "        target_index = word_to_index[target_word]\n",
        "\n",
        "        start = max(0, i - window_size)\n",
        "        end = min(len(corpus), i + window_size + 1)\n",
        "\n",
        "        context_words = [corpus[j] for j in range(start, end) if j != i]\n",
        "        for context_word in context_words:\n",
        "            context_index = word_to_index[context_word]\n",
        "            co_matrix[target_index, context_index] += 1\n",
        "\n",
        "    return co_matrix, words\n",
        "\n",
        "# Function to perform dimensionality reduction on the matrix to produce k-dimensional embeddings\n",
        "def dimensionality_reduction(co_matrix, k=2):\n",
        "    pca = PCA(n_components=k)\n",
        "    embeddings = pca.fit_transform(co_matrix)\n",
        "    return embeddings\n",
        "\n",
        "# Function to plot a set of 2D vectors in 2D space\n",
        "def plot_embeddings(embeddings, words):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i, word in enumerate(words):\n",
        "        plt.scatter(embeddings[i, 0], embeddings[i, 1], marker='o', color='blue')\n",
        "        plt.text(embeddings[i, 0] + 0.01, embeddings[i, 1] + 0.01, word, fontsize=9)\n",
        "\n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.title('2D Word Embeddings')\n",
        "    plt.show(block=True)\n",
        "\n",
        "# Load data and create embeddings\n",
        "corpus = [\"Sharry\", \"Maan\", \"is\", \"the\", \"greatest\", \"Singer\", \"of\", \"all\", \"the\", \"generation\"]\n",
        "co_matrix, words = co_occurrence_matrix(corpus)\n",
        "embeddings = dimensionality_reduction(co_matrix, k=2)\n",
        "\n",
        "# Call the plot function\n",
        "plot_embeddings(embeddings, words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"Sharry\", \"Maan\", \"is\", \"the\", \"greatest\", \"Singer\", \"of\", \"all\", \"the\", \"generation\"]\n",
        "distinct_words_list = distinct_words(corpus)\n",
        "print(distinct_words_list)"
      ],
      "metadata": {
        "id": "rXGHeZOhr8AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def distinct_words(corpus):\n",
        "    return list(set(corpus))\n",
        "\n",
        "corpus = [\"Sharry\", \"Maan\", \"is\", \"the\", \"greatest\", \"Singer\", \"of\", \"all\", \"the\", \"generation\"]\n",
        "\n",
        "# Call distinct_words to get the list of distinct words\n",
        "words = distinct_words(corpus)\n",
        "\n",
        "# Call co_occurrence_matrix to get the co-occurrence matrix\n",
        "co_matrix, words = co_occurrence_matrix(corpus)\n",
        "\n",
        "# Print the co-occurrence matrix and words\n",
        "print(\"Co-occurrence Matrix:\")\n",
        "print(co_matrix)\n",
        "print(\"\\nDistinct Words:\")\n",
        "print(words)"
      ],
      "metadata": {
        "id": "YUPm9Mi8sIV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already defined distinct_words and co_occurrence_matrix functions\n",
        "\n",
        "corpus = [\"Sharry\", \"Maan\", \"is\", \"the\", \"greatest\", \"Singer\", \"of\", \"all\", \"the\", \"generation\"]\n",
        "\n",
        "# Get the co-occurrence matrix\n",
        "co_matrix, words = co_occurrence_matrix(corpus)\n",
        "\n",
        "# Perform dimensionality reduction using PCA\n",
        "embeddings = dimensionality_reduction(co_matrix, k=2)\n",
        "\n",
        "# Print the reduced embeddings\n",
        "print(\"Reduced Embeddings:\")\n",
        "print(embeddings)\n",
        "\n",
        "# Visualize the 2D embeddings\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i, word in enumerate(words):\n",
        "    plt.scatter(embeddings[i, 0], embeddings[i, 1], marker='o', color='blue')\n",
        "    plt.text(embeddings[i, 0] + 0.01, embeddings[i, 1] + 0.01, word, fontsize=9)\n",
        "\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('2D Word Embeddings after Dimensionality Reduction')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hN93EFaFsWAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "corpus = [\"Gautam\", \"Gambhir\", \"is\", \"the\", \"greatest\", \"batsman\", \"of\", \"this\", \"world\"]\n",
        "\n",
        "# Define function to generate unique words\n",
        "def distinct_words(corpus):\n",
        "    return set(corpus)\n",
        "\n",
        "# Define function to create co-occurrence matrix\n",
        "def co_occurrence_matrix(corpus):\n",
        "    distinct_words = set(corpus)\n",
        "    co_matrix = np.zeros((len(distinct_words), len(distinct_words)))\n",
        "    for i, word1 in enumerate(distinct_words):\n",
        "        for j, word2 in enumerate(distinct_words):\n",
        "            co_matrix[i, j] = corpus.count(word2) if word1 != word2 else 0\n",
        "    return co_matrix, list(distinct_words)\n",
        "\n",
        "# Get the co-occurrence matrix\n",
        "co_matrix, words = co_occurrence_matrix(corpus)\n",
        "\n",
        "# Normalize the co-occurrence matrix\n",
        "co_matrix = normalize(co_matrix, axis=1)\n",
        "\n",
        "# Perform dimensionality reduction using PCA\n",
        "pca = PCA(n_components=2)\n",
        "embeddings = pca.fit_transform(co_matrix)\n",
        "\n",
        "# Plot the 2D vectors using matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, (embeddings[i, 0], embeddings[i, 1]))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9MV-LDvQskr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}